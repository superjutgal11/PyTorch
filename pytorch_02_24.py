# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11dArd7IeSZGEsrp0mY3wWbu81eSQLjHn
"""

import torch

ft = torch.FloatTensor([1,2,3,4])

print(ft)
print(ft.dtype)

print(ft.int())
print(ft.long())
print(ft.short())

x = torch.randn(1)
print(x)
print(x.item())
print(x.dtype)

""".to 메소드로 텐서를 cpu 혹은 gpu(cuda)로 옮길 수 있음.   
런타임 설정을 미리 해야 함.  

torch.device('위치')  
위치에 cuda넣으면 gpu 동작, cpu넣으면 cpu로 동작함.
"""

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(device)
y = torch.ones_like(x,device=device)
print(y)
x = x.to(device)
print(x)
z = x + y
print(z)
print(z.to('cpu',torch.double))

t0 = torch.tensor(3)
print(t0.ndim)
print(t0.shape)
print(t0)

t1 = torch.tensor([1,2,3,4])
print(t1.ndim)
print(t1.shape)
print(t1)

t2 = torch.tensor([[1,2,3,4],
                    [5,6,7,8],
                    [9,10,11,12]])
print(t2.ndim)
print(t2.shape)
print(t2)

t3 = torch.tensor([[[1,2,3,4],
                    [5,6,7,8],
                    [9,10,11,12]],
                   [[1,2,3,4],
                    [5,6,7,8],
                    [9,10,11,12]]])
print(t3.ndim)
print(t3.shape)
print(t3)

a = torch.rand(1,2) *2 -1
print(a)
print(torch.abs(a))
print(torch.floor(a))
print(torch.ceil(a))
print(torch.clamp(a,-0.5,0.5))

print(a)
print(torch.min(a))
print(torch.max(a))
print(torch.mean(a))
print(torch.std(a))
print(torch.prod(a))
print(torch.unique(torch.tensor([1,1,1,2,3,4,4,5,5])))

"""max와 min은 dim인자를 주면 argmax와 argmin도 함께 리턴한다."""

a = torch.rand(2,2)

print(a)
print(a.max(dim=0))
print(a.max(dim=1))